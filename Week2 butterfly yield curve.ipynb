{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRE-GY-6971, Homework #2, Due, 11/19/2017, 10am, 60 pts\n",
    "1. Definitions:\n",
    "I. Sample1: 1/31/2004 to 1/31/2006\n",
    "II. FLY: 3Y*0.5 – 7Y + 10Y*0.5, weights = (0.5,-1,0.5)\n",
    "III. WFLY: 3Y*w1 – 7Y + 10Y*w2, weights = (w1,-1,w2)\n",
    "IV. Combinations: FLY & various WFLYs\n",
    "2.\n",
    "a. Download the dataset ‘Daily_Treasury_Yield_Curve.xlsx’ into pandas dataframe & remove ‘1M column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 Mo', '6 Mo', '1 Yr', '2 Yr', '3 Yr', '5 Yr', '7 Yr', '10 Yr', '20 Yr']             3 Mo  6 Mo  1 Yr  2 Yr  3 Yr  5 Yr  7 Yr  10 Yr  20 Yr\n",
      "Date                                                              \n",
      "2004-02-02  0.94  1.03  1.29  1.83  2.36  3.18  3.70   4.18   5.02\n",
      "2004-02-03  0.94  1.02  1.27  1.78  2.30  3.12  3.65   4.13   4.98\n",
      "2004-02-04  0.94  1.01  1.27  1.80  2.32  3.15  3.67   4.15   5.00\n",
      "2004-02-05  0.94  1.02  1.29  1.85  2.40  3.21  3.72   4.20   5.02\n",
      "2004-02-06  0.93  1.01  1.26  1.77  2.29  3.12  3.63   4.12   4.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_excel('Daily_Treasury_Yield_Curve.xlsx', index_col = 0, parse_dates=True)\n",
    "#df.set_index('Date', inplace=True)\n",
    "del df['1 Mo']\n",
    "del df['30 Yr']\n",
    "d1 = '01/31/2004'\n",
    "d2 = '01/31/2006'\n",
    "df1 = df[d1 : d2]  #sample1\n",
    "\n",
    "#compute a table with daily changes:\n",
    "df_ret1 = df1.diff()\n",
    "df_ret1 = df_ret1.dropna(axis=0) #daily difference for sample1\n",
    "colname = df_ret1.columns.tolist()\n",
    "print(colname, df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Perform PCA using Sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08535373  0.14196683  0.23303966  0.37667945  0.40713671  0.42604973\n",
      "   0.40935272  0.3838078   0.33794751]\n",
      " [-0.54315013 -0.51670427 -0.46490225 -0.17964572 -0.03430887  0.09988564\n",
      "   0.19002765  0.23006288  0.29900548]\n",
      " [-0.56757509 -0.12617573  0.12853372  0.48611009  0.31294493  0.08407416\n",
      "  -0.1175822  -0.27325618 -0.46434552]]\n",
      "% variance explained:\n",
      "[ 0.8464  0.9271  0.9648  0.9816  0.9874  0.9918  0.9951  0.9977  0.9999]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sn\n",
    "pca = PCA(n_components=9)\n",
    "pca.fit(df_ret1)\n",
    "f=pca.components_#row: principal component, col: original features\n",
    "print(f[0:3,:])\n",
    "var_ratio = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4))\n",
    "print ('% variance explained:')\n",
    "print (var_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 3Y        7Y       10Y\n",
      "level      0.407137  0.409353  0.383808\n",
      "slope     -0.034309  0.190028  0.230063\n",
      "curvature  0.312945 -0.117582 -0.273256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x246c9f338d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD3CAYAAAAua/5EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwpiYJakw/wcRul8Nd4kcdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246c902e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comps = pd.DataFrame(f[0:3,[4,6,7]], columns = ['3Y','7Y','10Y'])#,rows = ['level','slope','curvature'])\n",
    "comps = comps.set_index([['level','slope','curvature']])\n",
    "#comps = comps.T\n",
    "#comps.rename(columns = {'level','slope','curvature'})\n",
    "print(comps)\n",
    "sn.heatmap(comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Compute weights of the WFLY to make sure that WFLY does not have PCA1,2 risk exposure in Sample1.\n",
    "Let’s call this combination WFLY1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights via PCA method:  [ 0.1988371   0.85563356]\n"
     ]
    }
   ],
   "source": [
    "##let 2 partical derivatives = 0\n",
    "formula1 = [ comps.loc['level','3Y'],comps.loc['level','10Y'] ]\n",
    "formula2 = [ comps.loc['slope','3Y'],comps.loc['slope','10Y'] ]\n",
    "a = np.array([formula1, formula2])\n",
    "response = [ comps.loc['level','7Y'],comps.loc['slope','7Y'] ]\n",
    "b = np.array(response)\n",
    "WFLY1 = np.linalg.solve(a, b)   #Computes the “exact” solution, x, of linear matrix equation ax = b\n",
    "print('weights via PCA method: ', WFLY1)\n",
    "\n",
    "#if use df1 as dataset, array([ 0.23723845,  0.83191551])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. Choose weights of the WFLY from cointegration analysis (weights correspond to the best cointegrated vector). \n",
    "Let’s call this combination WFLY2\n",
    "i. Use Box-Tiao or Chou-Ng estimation procedures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use CCA by Box-Tiao.\n",
    "\n",
    "Refer to the paper P363, the differenced series cannot be put into AR(1), so I use original data.\n",
    "\n",
    "It finds linear combinations of variables ranked in order of predictability by computing eigenvectors of Q (the matrix measure of predictibility). \n",
    "The bigger eigenvalues mean better predictibility while smaller eigenvalues have worse. \n",
    "Bad predictibility depends less on the past, which means more stationary.\n",
    "\n",
    "I find the eigenvector corresponding to least eigenvalue of Q, \n",
    "least predicitable - stationary and independent - reflect relationships which remains stable over the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65714382  0.9973796   0.95649773] [[ 0.17850857 -0.71091204 -0.26957127]\n",
      " [-0.7543349  -0.08153914  0.93572689]\n",
      " [ 0.63175435  0.69853807  0.2274786 ]]\n",
      "weights via CCA method - Box Tiao:  [ 0.23664365 -1.          0.83749851]\n"
     ]
    }
   ],
   "source": [
    "df_Box = df1.loc[:,['3 Yr','7 Yr','10 Yr']]\n",
    "mu = df_Box.mean()\n",
    "##remove mean, get stationary series\n",
    "df_B = df_Box - mu \n",
    "data_set1 = df_B.iloc[:-1,:]\n",
    "data_set2 = df_B.iloc[1:,:]\n",
    "#data_set1 = df_Box\n",
    "#data_set2 = data_set1.shift(1).dropna()#shift forward by one period--- wrong\n",
    "#or use formula(6) in mean revert paper: phiT = np.dot(np.dot(np.linalg.inv(np.dot(data_set1.T,data_set1)),data_set1.T),data_set2)\n",
    "phiT = np.linalg.lstsq(data_set1, data_set2)[0] # least-squares solution to a linear matrix equation data_set2 = data_set1*phiT\n",
    "#print(\"phi\",phiT)\n",
    "covz = data_set1.cov()\n",
    "##predictible measure Q\n",
    "#Q = np.dot( np.dot( np.dot(np.linalg.inv(covz), phiT.T), covz), phiT)\n",
    "Q = np.dot(np.linalg.inv(covz), np.dot(phiT.T,np.dot(covz,phiT)))\n",
    "val, vec = np.linalg.eig(Q)\n",
    "print(val, vec)\n",
    "eigi_pairs = [(val[i], vec[:,i]) for i in range(len(val))]\n",
    "eigi_pairs.sort(key=lambda x: x[0],reverse=False) #sort the eigenvalue from tuples from low to high\n",
    "##find the eigenvecotr to the least eigenvalue as weights\n",
    "weight = eigi_pairs[0][1]\n",
    "WFLY2 = np.array([-weight[0]/weight[1], -1, -weight[2]/weight[1]])\n",
    "print('weights via CCA method - Box Tiao: ', WFLY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the section above, we can see that weights calculated by PCA, CCA (Box & Tiao) are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute Half-Life & ADF statistic for FLY, WFLY1, WFLY2 using Sample1, compare results\n",
    "a. Note that you are considering time series of levels, not daily differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADF tests:\n",
    "The Augmented Dickey Fuller Test (ADF) is unit root test for stationarity. \n",
    "Unit roots can cause unpredictable results in your time series analysis. \n",
    "If all the unit roots are outside unit circle, the time series is stationary; otherwise not.\n",
    "\n",
    "Half-life of mean reversion gives the slowness of a mean-reversion process. Details: http://marcoagd.usuarios.rdc.puc-rio.br/half-life.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'statsmodels' to perform ADF test and OLS regression\n",
    "import statsmodels.tsa.stattools as tsa \n",
    "import statsmodels.api as sm \n",
    "\n",
    "# define a function: stationary test for each portfolio\n",
    "def stationary_test(data):\n",
    "    # compute ADF test statistic\n",
    "    adf_ = tsa.adfuller(data)\n",
    "    print('adf', adf_[0])\n",
    "    print('p-value', adf_[1])\n",
    "\n",
    "    #perform Half life\n",
    "    data_lag = data.shift(1)\n",
    "    Y = data[1:] - data_lag[1:]\n",
    "    X = sm.add_constant(data_lag[1:])  #Adds a column of ones to an array\n",
    "    model = sm.OLS(Y, X)\n",
    "    res = model.fit()\n",
    "    halflife = round(-np.log(2) / res.params[1], 0)  #E[dx] = h (m - x) dt, res.params[1] is h, dt = 1\n",
    "    print('Halflife = ', halflife)\n",
    "    #return adf_, halflife\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLY:\n",
      "adf -1.09424566268\n",
      "p-value 0.717361204362\n",
      "Halflife =  216.0\n",
      "\n",
      "WFLY1:\n",
      "adf -2.73113936472\n",
      "p-value 0.0688030559463\n",
      "Halflife =  12.0\n",
      "\n",
      "WFLY2:\n",
      "adf -2.23218373021\n",
      "p-value 0.194772616204\n",
      "Halflife =  32.0\n"
     ]
    }
   ],
   "source": [
    "# calculate portfolio on sample1\n",
    "df = df.loc[:,['3 Yr','7 Yr','10 Yr']]\n",
    "df1 = df[d1:d2]\n",
    "data_FLY = 0.5 * df1.loc[:, '3 Yr'] - df1.loc[:, '7 Yr'] + 0.5 * df1.loc[:, '10 Yr']\n",
    "#df1.loc['FLY'] = 0.5 * df1.loc[:, '3 Yr'] - df1.loc[:, '7 Yr'] + 0.5 * df1.loc[:, '10 Yr']\n",
    "data_WFLY1 = WFLY1[0] * df1.loc[:, '3 Yr'] - df1.loc[:, '7 Yr'] + WFLY1[1] * df1.loc[:, '10 Yr']\n",
    "data_WFLY2 = WFLY2[0] * df1.loc[:, '3 Yr'] - df1.loc[:, '7 Yr'] + WFLY2[1] * df1.loc[:, '10 Yr']\n",
    "\n",
    "#call the function stationary_test()\n",
    "print('FLY:')\n",
    "test_FLY = stationary_test(data_FLY)\n",
    "print('\\nWFLY1:')\n",
    "test_WFLY1 = stationary_test(data_WFLY1)\n",
    "print('\\nWFLY2:')\n",
    "test_WFLY2 = stationary_test(data_WFLY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare:\n",
    "The FLY on training samples are far from stationary (p-value 0.7) and have more than 200 days to go back to the mean. This portfolio is not good for a short-term trader.\n",
    "The PCA FLY on training sample(sample1) is stationary (p-value=0.0688), and this means that the first two components explains sample1 well.\n",
    "The stationary ability of CCA FLY on training samples are not so clear as p value is 0.19.\n",
    "The halflife of WFLY1 and WFLY2 are small, so the 2 models are relatively good in this sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repeat Step #3 out-of-sample: using 3m, 6m, 12m, 24m out of sample periods\n",
    "a. How do out-of-sample results compare across periods and combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3M sample:\n",
      "\n",
      "FLY:\n",
      "adf -0.46881063157\n",
      "p-value 0.897960535503\n",
      "Halflife =  8.0\n",
      "\n",
      "WFLY1:\n",
      "adf -0.844872800471\n",
      "p-value 0.805584497929\n",
      "Halflife =  15.0\n",
      "\n",
      "WFLY2:\n",
      "adf 1.59911516462\n",
      "p-value 0.997854918765\n",
      "Halflife =  62.0\n"
     ]
    }
   ],
   "source": [
    "# predict portfolio on out of sample 3M\n",
    "dftemp = df['02/01/2006':'04/30/2006']\n",
    "data_FLY = 0.5 * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + 0.5 * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY1 = WFLY1[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY1[1] * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY2 = WFLY2[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY2[1] * dftemp.loc[:, '10 Yr']\n",
    "\n",
    "print('3M sample:\\n')\n",
    "print('FLY:')\n",
    "stationary_test(data_FLY)\n",
    "print('\\nWFLY1:')\n",
    "stationary_test(data_WFLY1)\n",
    "print('\\nWFLY2:')\n",
    "stationary_test(data_WFLY2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6M sample:\n",
      "\n",
      "FLY:\n",
      "adf -1.57436309028\n",
      "p-value 0.496457676389\n",
      "Halflife =  4.0\n",
      "\n",
      "WFLY1:\n",
      "adf -1.35803560402\n",
      "p-value 0.602220968884\n",
      "Halflife =  11.0\n",
      "\n",
      "WFLY2:\n",
      "adf -1.76110448962\n",
      "p-value 0.399935944259\n",
      "Halflife =  24.0\n"
     ]
    }
   ],
   "source": [
    "# predict portfolio on out of sample 6M\n",
    "dftemp = df['02/01/2006':'07/31/2006']\n",
    "data_FLY = 0.5 * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + 0.5 * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY1 = WFLY1[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY1[1] * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY2 = WFLY2[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY2[1] * dftemp.loc[:, '10 Yr']\n",
    "print('6M sample:\\n')\n",
    "print('FLY:')\n",
    "stationary_test(data_FLY)\n",
    "print('\\nWFLY1:')\n",
    "stationary_test(data_WFLY1)\n",
    "print('\\nWFLY2:')\n",
    "stationary_test(data_WFLY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12M sample:\n",
      "\n",
      "FLY:\n",
      "adf -2.50570455532\n",
      "p-value 0.11409250744\n",
      "Halflife =  4.0\n",
      "\n",
      "WFLY1:\n",
      "adf -1.81627412952\n",
      "p-value 0.372412495653\n",
      "Halflife =  10.0\n",
      "\n",
      "WFLY2:\n",
      "adf -1.71620101965\n",
      "p-value 0.422785147851\n",
      "Halflife =  35.0\n"
     ]
    }
   ],
   "source": [
    "# predict portfolio on out of sample 12M\n",
    "dftemp = df['02/01/2006':'01/31/2007']\n",
    "data_FLY = 0.5 * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + 0.5 * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY1 = WFLY1[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY1[1] * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY2 = WFLY2[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY2[1] * dftemp.loc[:, '10 Yr']\n",
    "print('12M sample:\\n')\n",
    "print('FLY:')\n",
    "stationary_test(data_FLY)\n",
    "print('\\nWFLY1:')\n",
    "stationary_test(data_WFLY1)\n",
    "print('\\nWFLY2:')\n",
    "stationary_test(data_WFLY2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24M sample:\n",
      "\n",
      "FLY:\n",
      "adf 1.74239455697\n",
      "p-value 0.998227653688\n",
      "Halflife =  -313.0\n",
      "\n",
      "WFLY1:\n",
      "adf -0.78555390952\n",
      "p-value 0.823328711405\n",
      "Halflife =  28.0\n",
      "\n",
      "WFLY2:\n",
      "adf -0.13836446883\n",
      "p-value 0.945480661859\n",
      "Halflife =  785.0\n"
     ]
    }
   ],
   "source": [
    "# predict portfolio on out of sample 12M\n",
    "dftemp = df['02/01/2006':'01/31/2008']\n",
    "data_FLY = 0.5 * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + 0.5 * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY1 = WFLY1[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY1[1] * dftemp.loc[:, '10 Yr']\n",
    "data_WFLY2 = WFLY2[0] * dftemp.loc[:, '3 Yr'] - dftemp.loc[:, '7 Yr'] + WFLY2[1] * dftemp.loc[:, '10 Yr']\n",
    "print('24M sample:\\n')\n",
    "print('FLY:')\n",
    "stationary_test(data_FLY)\n",
    "print('\\nWFLY1:')\n",
    "stationary_test(data_WFLY1)\n",
    "print('\\nWFLY2:')\n",
    "stationary_test(data_WFLY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity:\n",
    "The original FLY on the test sampls have big p values(most of them are above 0.6), so FLY are far from stationary.\n",
    "\n",
    "Although the PCA FLY on traning samples are stationary, PCA FLY on test samples are ill-behaved (most of p-values are above 0.6). So, PCA FLY is not stable.\n",
    "\n",
    "For FLY CCA, it should be most stationary, but here I did not see any stationary properties.\n",
    "\n",
    "Half life:\n",
    "For most of the case, CCA FLY > PCA FLY > FLY.\n",
    "\n",
    "Across the periods:\n",
    "From the results of adf test, the portfolios are more stationary in 12M, and perform terribly in 24M.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q5\n",
    "Read d’Aspremont’s paper: Identifying Small Mean-Reverting Portfolios\n",
    "a. Explain the rationale for sparse decomposition algorithms\n",
    "b. Describe & compare results in Figures 1 and 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rationale for sparse decomposition algorithms:\n",
    "\n",
    "We want to solve the target(1):\n",
    "\n",
    "$$ maxmize   \\space  \\space { x^TAx \\over x^TBx }  $$\n",
    "$$ subject\\space to  \\space {Card(x)≤k \\space \\space ||x|| = 1}$$\n",
    "\n",
    "where k is a given constant and Card(x) is the number of nonzero coefficients in x. This will compute a sparse portfolio with maximum predicitibility.\n",
    "\n",
    "### Greedy Search\n",
    "\n",
    "This algorithm does recursively. Suppose we have a good prroximate solution with support set  $I_{k}$. We add a variable with index  $I_{k+1}$ to set $I_{k}$ to produce the largest increase in predictability in  $I_{k}^{c}$. Then we repeat this process until k=n.\n",
    "\n",
    "### Semidefinite Relaxation\n",
    "\n",
    "We drop nonconvex constraint $Card(X) ≤ k^{2}$ and then rewrite the target(1) as the following: \n",
    "\n",
    "$$maximize \\space \\space {Tr(AY)} $$\n",
    " \n",
    " $$subject\\space to \\space \\space {1^{T}|Y|1 − kz ≤ 0}$$\n",
    " \n",
    " $$Tr(Y) − z = 0$$\n",
    " \n",
    " $$Tr(BY ) = 1$$\n",
    " \n",
    "$$Y >= 0$$\n",
    "Which is a semidefinite program(SDP) in the variables Y∈$S_n$ and z∈$R_+$ and can be solved using standard SDP solvers.\n",
    "\n",
    "### Comparison\n",
    "\n",
    "The computational complexity of greedy search is smaller than semidefinite relaxation. But the solution of greedy search is far from optimal while the performance of the solutions produced by semidefinite relaxation is often higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description \n",
    "Figure 1 describes Box-Tiao decomposition on 100 days of US swap rate data. The eight canonical portfolios of swap rates with maturities ranging from one to thirty yearsare ranked in decreasing order of predictability. The mean reversion coefficient λ. \n",
    "\n",
    "Figure 2 describes Sparse canonical decomposition on 100 days of U.S. swap rates data. The eight canonical portfolios of swap rates with the mean reversion coefficient λ and number of nonzero coefficients in each portfolio vector k.  \n",
    "\n",
    "### Comparsion\n",
    "The distriution of k in Figure2 is more dense than in Figure1. Like the last 2 graphs in Figure2, mean reversion coefficients λ are same as 252. \n",
    "In addition, we could see the mean reversion become more obvious in Figure2 than Figure1 when k is bigger. So, the property of mean reversion using sparse decomposition converges more quickly than using Box-Tian. From my perspective, with a given k, the portfolio constructed by sparse decomposition might have less contraints, so, the portfolio might have less predictability. In practice, sparse decompostion is easier for us to find a mean reversion trading strategy than Box-Tiao. But we need to compare the results when the 2 algos are appied on out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
